# -*- coding: utf-8 -*-
"""Password Strength.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LKPCMLA0h2SE4ZKJDLzFzFVElcxML5Ch
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv(r'/content/drive/MyDrive/Password Strength/data.csv',error_bad_lines=False)
df.head()

df['strength'].unique()

df.isna().sum()

df[df['password'].isnull()]

df.dropna(inplace=True)

df.info()

# Plot
plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='strength')
plt.title('Count Plot of Strength')
plt.xlabel('Strength')
plt.ylabel('Count')
plt.show()

sns.countplot(data=df,x='strength')

password_tuple=np.array(df)

password_tuple

import random

random.shuffle(password_tuple)

x=[labels[0] for labels in password_tuple]
y=[labels[1] for labels in password_tuple]

x

# defining the fuction to split it into characters

def word_divide_char(inputs):
  character=[]
  for i in inputs:
    character.append(i)

  return character

word_divide_char('vertikal12')

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer=TfidfVectorizer(tokenizer=word_divide_char)

X=vectorizer.fit_transform(x)

X.shape

vectorizer.get_feature_names_out()

first_document_vector=X[0]

first_document_vector

first_document_vector.T.todense()

df1=pd.DataFrame(first_document_vector.T.todense(),index=vectorizer.get_feature_names_out(),columns=['TF_IDF'])

df1.head()

df1.sort_values(by=['TF_IDF'],ascending=False)

from sklearn.model_selection  import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)

X_train.shape

from sklearn.linear_model import LogisticRegression

clf=LogisticRegression(random_state=0,multi_class='multinomial')

clf.fit(X_train,y_train)

dt=np.array(['Casper@99'])
pred=vectorizer.transform(df)

clf.predict(pred)

y_pred=clf.predict(X_test)

y_pred

from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

confusion_matrix(y_test,y_pred)

accuracy_score(y_test,y_pred)

print(classification_report(y_test,y_pred))

